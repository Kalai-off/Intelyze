import json, pathlib, tempfile, os
from datetime import datetime, UTC
from dotenv import load_dotenv
from agents import Agent, Runner, CodeInterpreterTool, trace,ModelSettings
from hooks.run_hook import RunHook
from engine.engine_system_prompt import Engine_system_prompt
import threading

from typing import List, Optional
from pydantic import BaseModel, Field

load_dotenv()
run_hook = RunHook()


CONV_HISTORY_FILE = os.path.join(os.path.dirname(__file__), "session_management", "session_model_interaction.json")

def load_all_conversations():
    if not os.path.exists(CONV_HISTORY_FILE):
        return []
    with open(CONV_HISTORY_FILE, "r", encoding="utf-8") as f:
        return json.load(f)

def save_all_conversations(convs):
    with open(CONV_HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(convs, f, indent=2, ensure_ascii=False)

    # Background sync of the conversation file only (best-effort)
    try:
        def _bg_sync_conv_file(file_path):
            try:
                from sync.remote_sync import sync_path
                # Send the single conversation file; remote key mirrors session_management/<filename>
                filename = pathlib.Path(file_path).name
                remote_subpath = f"session_management/{filename}"
                sync_path(file_path, remote_subpath=remote_subpath)
            except Exception as e:
                print("orchestrator: background conversation file sync failed:", e)

        t = threading.Thread(target=_bg_sync_conv_file, args=(CONV_HISTORY_FILE,), daemon=True)
        t.start()
    except Exception:
        pass

def get_conversation(session_id):
    convs = load_all_conversations()
    for conv in convs:
        if conv["session_id"] == session_id:
            return conv
    return None

def save_model_interaction(session_id, model_interaction):
    convs = load_all_conversations()
    for conv in convs:
        if conv["session_id"] == session_id:
            conv["model_interaction"] = model_interaction
            break
    else:
        convs.append({
            "session_id": session_id,
            "model_interaction": model_interaction
        })
    save_all_conversations(convs)


class output_type(BaseModel):
    reasoning: str = Field(..., description="The reasoning steps taken to arrive at the final output")
    response: str = Field(..., description="The final output generated by the model")

# ───────────────── orchestrator class ───────────────────────────────
class Orchestrator:
    def __init__(self):
        self.user_sessions = {}

    def load_conversation_history(self, session_id):
        conv = get_conversation(session_id)
        if conv:
            return conv.get("model_interaction", [])
        return []
    

    def save_conversation_history(self, session_id, history):
        save_model_interaction(session_id, history)
    # ---------- public entry ----------------------------------------
    def process_user_query(self, text: str, sid: str, file_ids: list[str] | None = None):
        # Load existing model interaction for this session
        model_interaction = self.load_conversation_history(sid)
        model_interaction.append({"content": text, "role": "user"})
        self.save_conversation_history(sid, model_interaction) 

        # 2️⃣  build agent with today’s file_ids
        tool_cfg = {
            "type": "code_interpreter",
            "container": {"type": "auto", "file_ids": file_ids or []}
        }
        agent = Agent(
            name="engine",
            model="o3",
            model_settings = ModelSettings(
                        reasoning={"effort": "medium","summary": None},
                        response_include=["reasoning.encrypted_content","code_interpreter_call.outputs" ],
                    ),

            instructions=Engine_system_prompt().get_system_prompt(),
            tools=[CodeInterpreterTool(tool_config=tool_cfg)],
        )

        # 3️⃣  run; convert every message to plain dict before saving
        with trace("Excel Insights"):

            run = Runner.run_sync(agent, input=model_interaction, hooks=run_hook, max_turns= 2)
            # Convert output_type instance to JSON string for serialization
            model_interaction = run.to_input_list()

            self.save_conversation_history(sid, model_interaction)

        return run.final_output
